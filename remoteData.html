<!DOCTYPE html>
<html lang="en" dir="ltr" prefix="og: http://ogp.me/ns# content: http://purl.org/rss/1.0/modules/content/ dc: http://purl.org/dc/terms/ foaf: http://xmlns.com/foaf/0.1/ rdfs: http://www.w3.org/2000/01/rdf-schema# sioc: http://rdfs.org/sioc/ns# sioct: http://rdfs.org/sioc/types# skos: http://www.w3.org/2004/02/skos/core# xsd: http://www.w3.org/2001/XMLSchema#">
<head>
  <link rel="profile" href="http://www.w3.org/1999/xhtml/vocab" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="google-site-verification" content="I6-kCnsGJSr7I2jjHFvsLD5KbfCgQcJlcpEIhWB-81U" />
  <meta name="description" content="Virtual Hackerspace and Resources for Software Developers of all Skill Levels." />
  <meta property="og:image" content="https://www.devdungeon.com/sites/default/static/devdungeon500x500.png" />

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-P4J4SB');</script>
  <!-- End Google Tag Manager -->

  <!-- Start of HubSpot Embed Code -->
 <!-- <script type="text/javascript" id="hs-script-loader" async defer src="//js.hs-scripts.com/3075403.js"></script> -->
  <!-- End of HubSpot Embed Code -->

  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="shortcut icon" href="https://www.devdungeon.com/sites/all/themes/devdungeon2/favicon.ico" type="image/vnd.microsoft.icon" />
<meta name="description" content="Web scraping (Wikipedia entry) is a handy tool to have in your arsenal. It can be useful in a variety of situations, like when a website does not provide an API, or you need to parse and extract web content programmatically. This tutorial walks through using the standard library to perform a variety of tasks like making requests, changing headers, setting cookies, using" />
<meta name="generator" content="Drupal 7 (https://www.drupal.org)" />
<link rel="canonical" href="https://www.devdungeon.com/content/web-scraping-go" />
<link rel="shortlink" href="https://www.devdungeon.com/node/195" />
<meta property="og:site_name" content="DevDungeon" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.devdungeon.com/content/web-scraping-go" />
<meta property="og:title" content="Web Scraping with Go" />
<meta property="og:description" content="Web scraping (Wikipedia entry) is a handy tool to have in your arsenal. It can be useful in a variety of situations, like when a website does not provide an API, or you need to parse and extract web content programmatically. This tutorial walks through using the standard library to perform a variety of tasks like making requests, changing headers, setting cookies, using regular expressions, and parsing URLs. It also covers the basics of the goquery package (a jQuery like tool) to scrape information from an HTML web page on the internet. If you need to reverse engineering a web application based on the network traffic, it may also be helpful to learn how to do packet capture, injection, and analysis with Gopacket. If you are downloading and storing content from a site you scrape, you may be interested in working with files in Go." />
<meta property="og:updated_time" content="2018-03-25T16:44:47-05:00" />
<meta property="article:published_time" content="2018-03-24T20:43:06-05:00" />
<meta property="article:modified_time" content="2018-03-25T16:44:47-05:00" />
<meta name="dcterms.title" content="Web Scraping with Go" />
<meta name="dcterms.creator" content="NanoDano" />
<meta name="dcterms.description" content="Web scraping (Wikipedia entry) is a handy tool to have in your arsenal. It can be useful in a variety of situations, like when a website does not provide an API, or you need to parse and extract web content programmatically. This tutorial walks through using the standard library to perform a variety of tasks like making requests, changing headers, setting cookies, using regular expressions, and parsing URLs. It also covers the basics of the goquery package (a jQuery like tool) to scrape information from an HTML web page on the internet. If you need to reverse engineering a web application based on the network traffic, it may also be helpful to learn how to do packet capture, injection, and analysis with Gopacket. If you are downloading and storing content from a site you scrape, you may be interested in working with files in Go." />
<meta name="dcterms.date" content="2018-03-24T20:43-05:00" />
<meta name="dcterms.type" content="Text" />
<meta name="dcterms.format" content="text/html" />
<meta name="dcterms.identifier" content="https://www.devdungeon.com/content/web-scraping-go" />
<meta name="dcterms.language" content="en" />
  <title>Web Scraping with Go | DevDungeon</title>
  <link type="text/css" rel="stylesheet" href="https://www.devdungeon.com/sites/default/files/css/css_lQaZfjVpwP_oGNqdtWCSpJT1EMqXdMiU84ekLLxQnc4.css" media="all" />
<link type="text/css" rel="stylesheet" href="https://www.devdungeon.com/sites/default/files/css/css_drCT3RW3QvBZhuq2WTTyq55k_fzEuqiWFI6N_W3_3qI.css" media="all" />
<link type="text/css" rel="stylesheet" href="https://www.devdungeon.com/sites/default/files/css/css_RQ2JVk93qGnRd2q_Cy8kNtNJek2c1_j11q9Rwx8v1GE.css" media="all" />
<link type="text/css" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@3.3.5/dist/css/bootstrap.min.css" media="all" />
<link type="text/css" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@unicorn-fail/drupal-bootstrap-styles@0.0.2/dist/3.3.1/7.x-3.x/drupal-bootstrap.min.css" media="all" />
<link type="text/css" rel="stylesheet" href="https://www.devdungeon.com/sites/default/files/css/css_S7uW7EqfiGzoV349Nw8LuCw-260ePlP84yZOc7oKAGE.css" media="all" />
<link type="text/css" rel="stylesheet" href="https://www.devdungeon.com/sites/default/files/css/css_DqiuSTbynplXJ3hy5abg6z0YV95ZsETceC1DnBGkts4.css" media="all" />
  <!-- HTML5 element support for IE6-8 -->
  <!--[if lt IE 9]>
    <script src="https://cdn.jsdelivr.net/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <script>window.google_analytics_uacct = "UA-12366646-5";</script>
<script src="https://www.devdungeon.com/sites/default/files/js/js_s5koNMBdK4BqfHyHNPWCXIL2zD0jFcPyejDZsryApj0.js"></script>
<script src="https://www.devdungeon.com/sites/default/files/js/js_itRbSIFwmIXXAzBj95K4rYG9VewmgrkrpA0P_WEk-S8.js"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@3.3.5/dist/js/bootstrap.min.js"></script>
<script src="https://www.devdungeon.com/sites/default/files/js/js_R9UbiVw2xuTUI0GZoaqMDOdX0lrZtgX-ono8RVOUEVc.js"></script>
<script src="https://www.devdungeon.com/sites/default/files/js/js_mk8Yt8Jy6gPaSsiuNIEVPBD0G-I0ojJMM5MfRye4mrc.js"></script>
<script>(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,"script","https://www.google-analytics.com/analytics.js","ga");ga("create", "UA-12366646-5", {"cookieDomain":"auto"});ga("send", "pageview");</script>
<script src="https://www.devdungeon.com/sites/default/files/js/js_tzEGTRyjbSNo4GS4Eh6_ZJb5BgaDvQF9UshkdxwThp0.js"></script>
<script>jQuery.extend(Drupal.settings, {"basePath":"\/","pathPrefix":"","setHasJsCookie":0,"ajaxPageState":{"theme":"devdungeon2","theme_token":"3IPWj4AI2gITb-vJxmllGwQI01CZ9ofXU35fbh1Z25I","js":{"sites\/all\/themes\/bootstrap\/js\/bootstrap.js":1,"0":1,"sites\/all\/modules\/contrib\/jquery_update\/replace\/jquery\/1.10\/jquery.min.js":1,"misc\/jquery-extend-3.4.0.js":1,"misc\/jquery-html-prefilter-3.5.0-backport.js":1,"misc\/jquery.once.js":1,"misc\/drupal.js":1,"sites\/all\/libraries\/prettify\/src\/prettify.js":1,"sites\/all\/libraries\/prettify\/src\/lang-css.js":1,"sites\/all\/libraries\/prettify\/src\/lang-sql.js":1,"sites\/all\/libraries\/prettify\/src\/lang-yaml.js":1,"https:\/\/cdn.jsdelivr.net\/npm\/bootstrap@3.3.5\/dist\/js\/bootstrap.min.js":1,"sites\/all\/modules\/contrib\/admin_menu\/admin_devel\/admin_devel.js":1,"sites\/all\/libraries\/colorbox\/jquery.colorbox-min.js":1,"sites\/all\/modules\/contrib\/colorbox\/js\/colorbox.js":1,"sites\/all\/modules\/contrib\/colorbox\/styles\/default\/colorbox_style.js":1,"sites\/all\/modules\/contrib\/prettify\/prettify.loader.js":1,"sites\/all\/modules\/contrib\/google_analytics\/googleanalytics.js":1,"1":1,"sites\/all\/modules\/contrib\/disqus\/disqus.js":1},"css":{"modules\/system\/system.base.css":1,"modules\/field\/theme\/field.css":1,"modules\/node\/node.css":1,"sites\/all\/modules\/contrib\/toc_node\/css\/toc_node.css":1,"sites\/all\/modules\/contrib\/youtube\/css\/youtube.css":1,"sites\/all\/modules\/contrib\/views\/css\/views.css":1,"sites\/all\/modules\/contrib\/colorbox\/styles\/default\/colorbox_style.css":1,"sites\/all\/modules\/contrib\/ctools\/css\/ctools.css":1,"sites\/all\/modules\/contrib\/tagclouds\/tagclouds.css":1,"https:\/\/cdn.jsdelivr.net\/npm\/bootstrap@3.3.5\/dist\/css\/bootstrap.min.css":1,"https:\/\/cdn.jsdelivr.net\/npm\/@unicorn-fail\/drupal-bootstrap-styles@0.0.2\/dist\/3.3.1\/7.x-3.x\/drupal-bootstrap.min.css":1,"sites\/all\/themes\/devdungeon2\/css\/style.css":1,"sites\/all\/modules\/contrib\/prettify\/styles\/desert.css":1}},"colorbox":{"opacity":"0.85","current":"{current} of {total}","previous":"\u00ab Prev","next":"Next \u00bb","close":"Close","maxWidth":"98%","maxHeight":"98%","fixed":true,"mobiledetect":true,"mobiledevicewidth":"480px","specificPagesDefaultValue":"admin*\nimagebrowser*\nimg_assist*\nimce*\nnode\/add\/*\nnode\/*\/edit\nprint\/*\nprintpdf\/*\nsystem\/ajax\nsystem\/ajax\/*"},"prettify":{"linenums":false,"match":"article","nocode":"no-code","custom":[],"markup":{"code":true,"pre":true,"precode":false}},"googleanalytics":{"trackOutbound":1,"trackMailto":1,"trackDownload":1,"trackDownloadExtensions":"7z|aac|arc|arj|asf|asx|avi|bin|csv|doc(x|m)?|dot(x|m)?|exe|flv|gif|gz|gzip|hqx|jar|jpe?g|js|mp(2|3|4|e?g)|mov(ie)?|msi|msp|pdf|phps|png|ppt(x|m)?|pot(x|m)?|pps(x|m)?|ppam|sld(x|m)?|thmx|qtm?|ra(m|r)?|sea|sit|tar|tgz|torrent|txt|wav|wma|wmv|wpd|xls(x|m|b)?|xlt(x|m)|xlam|xml|z|zip","trackColorbox":1},"disqus":{"domain":"devdungeon","url":"https:\/\/www.devdungeon.com\/content\/web-scraping-go","title":"Web Scraping with Go","identifier":"node\/195"},"urlIsAjaxTrusted":{"\/content\/web-scraping-go":true},"bootstrap":{"anchorsFix":"0","anchorsSmoothScrolling":"0","formHasError":1,"popoverEnabled":1,"popoverOptions":{"animation":1,"html":0,"placement":"right","selector":"","trigger":"click","triggerAutoclose":1,"title":"","content":"","delay":0,"container":"body"},"tooltipEnabled":1,"tooltipOptions":{"animation":1,"html":0,"placement":"auto left","selector":"","trigger":"hover focus","delay":0,"container":"body"}}});</script>






<!-- Google AdSense code -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6890888622534407"
     crossorigin="anonymous"></script>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>



<!-- popdown menu -->
<style>
/* popdown from top menu */
#popdown {
	position: absolute;
	z-index: 101;
	top: -20px;
	left: 0;
	right: 0;
	background: #005c52;
	text-align: center;
	line-height: 2.5;
	overflow: hidden;
	-webkit-box-shadow: 0 0 5px black;
	-moz-box-shadow: 0 0 5px black;
	box-shadow: 0 0 5px black;
}
@-webkit-keyframes slideDown {
    0%, 100% { -webkit-transform: translateY(-50px); }
    10%, 90% { -webkit-transform: translateY(0px); }
}
@-moz-keyframes slideDown {
    0%, 100% { -moz-transform: translateY(-50px); }
    10%, 90% { -moz-transform: translateY(0px); }
}
.cssanimations.csstransforms #popdown {
    -webkit-transform: translateY(-50px);
    -webkit-animation: slideDown 2.5s 1.0s 1 ease forwards;
    -moz-transform:    translateY(-50px);
    -moz-animation:    slideDown 2.5s 1.0s 1 ease forwards;
}
.cssanimations.csstransforms #close {
  display: none;
}
/* end popdown from top */
</style>
<script>


function closePopdown() {
   popdown = document.getElementById("popdown");
   popdown.style.display = 'none';
 }
function incrementClicks() {
  ga('send', {
  hitType: 'event',
  eventCategory: 'PrivateLessonSignup',  eventAction: 'Click',
  eventLabel: 'PopdownAlert-PrivateLessonSignup'
});
}
</script>



</head>
<body class="html not-front not-logged-in one-sidebar sidebar-second page-node page-node- page-node-195 node-type-blog">

  <!-- popdown menu -->



  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-P4J4SB"
                    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  <div id="skip-link">
    <a href="#main-content" class="element-invisible element-focusable">Skip to main content</a>
  </div>
    <header id="navbar" role="banner" class="navbar container navbar-default">
  <div class="container">
    <div class="navbar-header">
              <a class="logo navbar-btn pull-left" href="/" title="Home">
          <img src="https://www.devdungeon.com/sites/all/themes/devdungeon2/logo.png" alt="Home" />
        </a>
      
              <a class="name navbar-brand" href="/" title="Home">DevDungeon</a>
      
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar-collapse">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
          </div>

          <div class="navbar-collapse collapse" id="navbar-collapse">
        <nav role="navigation">
                      <ul class="menu nav navbar-nav"><li class="first leaf"><a href="/" title="">Home</a></li>
<li class="expanded dropdown"><a href="/content/languages" title="Programming languages" class="dropdown-toggle" data-toggle="dropdown">Languages <span class="caret"></span></a><ul class="dropdown-menu"><li class="first leaf"><a href="/content/languages" title="List to all programming language pages">-- See all languages --</a></li>
<li class="leaf"><a href="/content/c" title="">C/C++</a></li>
<li class="leaf"><a href="/content/go" title="Go posts">Go</a></li>
<li class="leaf"><a href="/content/python" title="Resources for Python programmers">Python</a></li>
<li class="leaf"><a href="/content/javascript" title="">JavaScript/TypeScript</a></li>
<li class="leaf"><a href="/content/java" title="">Java</a></li>
<li class="leaf"><a href="/content/php" title="PHP posts">PHP</a></li>
<li class="leaf"><a href="/content/ruby" title="Ruby posts">Ruby</a></li>
<li class="last leaf"><a href="/content/rust" title="Rust posts">Rust</a></li>
</ul></li>
<li class="expanded dropdown"><a href="/topics" title="Categories of posts" class="dropdown-toggle" data-toggle="dropdown">Topics <span class="caret"></span></a><ul class="dropdown-menu"><li class="first leaf"><a href="/topics" title="All topics/tags">-- See all topics --</a></li>
<li class="leaf"><a href="/content/creative-coding" title="Creative Coding and Generative Art with Processing/p5.js">Creative Coding</a></li>
<li class="leaf"><a href="/content/android" title="Android related posts">Android</a></li>
<li class="leaf"><a href="/content/arduino" title="Arduino posts">Arduino</a></li>
<li class="leaf"><a href="/content/minecraft" title="Minecraft related things">Minecraft</a></li>
<li class="leaf"><a href="/content/philosophy-soft-skills" title="Philosophy and soft skill topics">Philosophy &amp; Soft Skills</a></li>
<li class="leaf"><a href="/content/sqlite" title="SQlite3 tutorials">SQLite</a></li>
<li class="last leaf"><a href="/content/sysadmin" title="System administrator related posts">Sysadmin</a></li>
</ul></li>
<li class="expanded dropdown"><a href="/projects" title="DevDungeon Software Projects" class="dropdown-toggle" data-toggle="dropdown">Projects <span class="caret"></span></a><ul class="dropdown-menu"><li class="first leaf"><a href="/projects" title="DevDungeon Software Projects">-- See all Projects --</a></li>
<li class="leaf"><a href="/content/binaural-beat-generator">Binaural Beat Generator</a></li>
<li class="leaf"><a href="/content/cathy-chat-bot" title="AI chat bot for Discord written in Python using AIML library">Cathy Chat Bot</a></li>
<li class="leaf"><a href="/cookbook" title="">Cookbook</a></li>
<li class="leaf"><a href="/devnix" title="DevNix: a Fedora Remix">DevNix</a></li>
<li class="leaf"><a href="/content/help-desk-bot" title="Help Desk Bot - Discord Utility Bot written in Python 3">Help Desk Bot</a></li>
<li class="leaf"><a href="/content/ip2kml">Ip2Kml</a></li>
<li class="leaf"><a href="/content/issh">ISSH</a></li>
<li class="leaf"><a href="/content/mysql2excel" title="Dump MySQL table to Excel spreadsheet">mysql2excel</a></li>
<li class="leaf"><a href="/content/nanolife" title="John Conway&#039;s Game of Life written in Ruby">NanoLife</a></li>
<li class="leaf"><a href="/content/rest-tester" title="REST Tester Software Project">Rest Tester</a></li>
<li class="leaf"><a href="/content/tcp-null">TCP Null</a></li>
<li class="last leaf"><a href="/content/web-genome" title="Web Genome Project">Web Genome</a></li>
</ul></li>
<li class="leaf"><a href="/archive" title="All blog posts and videos">Archive</a></li>
<li class="leaf"><a href="https://www.devdungeon.com/wiki" title="Wiki">Wiki</a></li>
<li class="leaf"><a href="/books" title="My books">Books</a></li>
<li class="leaf"><a href="/courses" title="My courses">Courses</a></li>
<li class="last leaf"><a href="/content/about-me" title="">About</a></li>
</ul>                                      </nav>
      </div>
      </div>
</header>

<div class="main-container container">

  <header role="banner" id="page-header">
    
      </header> <!-- /#page-header -->

  <div class="row">

    
    <section class="col-sm-9">
                  <a id="main-content"></a>
                    <h1 class="page-header">Web Scraping with Go</h1>
                                                          <div class="region region-content">
    <section id="block-block-14" class="block block-block clearfix">

      
  <center>
<p style="font-size: 50%;">Advertisement</p>
<!-- 728x90Leaderboard -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-6890888622534407"
     data-ad-slot="9701133649"
     data-ad-format="auto"></ins>
<p style="font-size: 50%;">Advertisement</p>
</center>

</section>
<section id="block-system-main" class="block block-system clearfix">

      
  <article id="node-195" class="node node-blog node-promoted clearfix" about="/content/web-scraping-go" typeof="sioc:Post sioct:BlogPost">
    <header>
            <span property="dc:title" content="Web Scraping with Go" class="rdf-meta element-hidden"></span>  </header>
        <span class="submitted">
        <span property="dc:date dc:created" content="2018-03-24T20:43:06-05:00" datatype="xsd:dateTime" rel="sioc:has_creator">Submitted by <a href="/users/nanodano" title="View user profile." class="username" xml:lang="" about="/users/nanodano" typeof="sioc:UserAccount" property="foaf:name" datatype="">NanoDano</a> on Sat, 03/24/2018 - 20:43</span>    </span>
      <div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even" property="content:encoded"><h2>Overview</h2>

<ul>
    <li><a href="#intro">Introduction</a></li>
    <li><a href="#ethics_and_guidelines">Ethics and guidelines of scraping</a></li>
    <li><a href="#prerequisites">Prerequisites</a></li>
    <li><a href="#make_http_get_request">Make an HTTP GET request</a></li>
    <li><a href="#make_http_get_request_with_timeout">Make an HTTP GET request with timeout</a></li>
    <li><a href="#set_http_headers_change_user_agent">Set HTTP headers (Change user agent)</a></li>
    <li><a href="#download_a_url">Download a URL</a></li>
    <li><a href="#substring_matching">Use substring matching to find page title</a></li>
    <li><a href="#using_regular_expressions_to_find_html_comments">Use regular expressions to find HTML comments</a></li>
    <li><a href="#find_all_links_on_page">Use goquery to find all links on a page</a></li>
    <li><a href="#parse_urls">Parse URLs</a></li>
    <li><a href="#find_all_images_on_page">Use goquery to find all images on a page</a></li>
    <li><a href="#make_http_post_request_with_data">Make an HTTP POST request with data</a></li>
    <li><a href="#make_http_request_with_cookie">Make HTTP request with cookie</a></li>
    <li><a href="#log_in_to_website">Log in to a website</a></li>
    <li><a href="#crawling">Web crawling</a></li>
    <li><a href="#webgenome_project">DevDungeon Project: Web Genome - http://www.webgeno.me</a></li>
    <li><a href="#conclusion">Conclusion</a></li>
</ul>



<a name="intro"></a>
<h2>Introduction</h2>

<p>Web scraping (<a href="https://en.wikipedia.org/wiki/Web_scraping" target="_blank">Wikipedia entry</a>) is a handy tool to have in your arsenal. It can be useful in a variety of situations, like when a website does not provide an API, or you need to parse and extract web content programmatically. This tutorial walks through using the standard library to perform a variety of tasks like making requests, changing headers, setting cookies, using regular expressions, and parsing URLs. It also covers the basics of the <strong>goquery</strong> package (a jQuery like tool) to scrape information from an HTML web page on the internet.</p>

<p>If you need to reverse engineering a web application based on the network traffic, it may also be helpful to learn how to do <a href="/content/packet-capture-injection-and-analysis-gopacket">packet capture, injection, and analysis with Gopacket</a>.</p>

<p>If you are downloading and storing content from a site you scrape, you may be interested in <a href="/content/working-files-go">working with files in Go</a>.


<a name="ethics_and_guidelines"></a>
<h2>Ethics and guidelines of scraping</h2>

<p>Before doing any web scraping, it is important to understand what you are doing technically. If you use this information irresponsibly, you could potentially cause a denial-of-service, incur bandwidth costs to yourself or the website provider, overload log files, or otherwise stress computing resources. If you are unsure of the repercussions of your actions, do not perform any scraping without consulting a knowledgable person. You are responsible for the actions you take including any cost or repercussion that comes along with it.</p>

<p>When doing any scraping or crawling, you should be considerate of the server owners and use good rate limiting, prevent overloading a single site, and use reasonable settings and limits.</p>

<p>It is important to understand that some sites have terms of service that do not allow scraping. While you might not face legal problems, they could ban your account if you have one, block your IP address, or otherwise revoke your access to the website or service. Before scraping any site, find out if there are any rules or guidelines explicitly stated in the terms of service.</p>

<o>Also keep in mind that some websites do provide APIs. Check to see if an API is avaiable before scraping. If a website or service provides an API, you should use that. APIs are intended to be used programmatically and are also much more efficient.</o>



<a name="prerequisites"></a>
<h2>Prerequisites</h2>

<ul>
 <li><a href="https://golang.org" target="_blank">Go</a> - The Go programming language (tested with 1.6)</p></li>
 <li><a href="https://github.com/PuerkitoBio/goquery" target="_blank">goquery</a> (for some examples) - Go version of jQuery for DOM parsing</li>
</ul>

<p>The only dependency, other than Go itself, is the goquery package. Goquery is not needed for every example, as the majority of examples rely only on the standard library. To install the <strong>goquery</strong> dependency, use <strong>go get</strong>:</p>

<pre class="prettyprint"><code>go get github.com/PuerkitoBio/goquery</code></pre>

<p>If you have issues with your $GOPATH when using <strong>go get</strong>, be sure to read up about <a href="https://golang.org/doc/code.html#Workspaces" target="_blank">Workspaces</a> and <a href="https://golang.org/doc/code.html#GOPATH" target="_blank">the GOPATH environment variable</a> and make sure you have a <strong>GOPATH</strong> set.</p>





<a name="make_http_get_request"></a>
<h2>Make an HTTP GET request</h2>
<p>The first step to web scraping is being able to make an HTTP request. Let's look a very basic HTTP GET request and how to check the response code and view the content. Note the default timeout of an HTTP request using the default <strong>transport</strong> is forever.</p>

<pre class="prettyprint"><code>// make_http_request.go<br />package main<br /><br />import (<br />&nbsp;&nbsp;&nbsp; &quot;io&quot;<br />&nbsp;&nbsp;&nbsp; &quot;log&quot;<br />&nbsp;&nbsp;&nbsp; &quot;net/http&quot;<br />&nbsp;&nbsp;&nbsp; &quot;os&quot;<br />)<br /><br />func main() {<br />&nbsp;&nbsp;&nbsp; // Make HTTP GET request<br />&nbsp;&nbsp;&nbsp; response, err := http.Get(&quot;https://www.devdungeon.com/&quot;)<br />&nbsp;&nbsp;&nbsp; if err != nil {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; log.Fatal(err)<br />&nbsp;&nbsp;&nbsp; }<br />&nbsp;&nbsp;&nbsp; defer response.Body.Close()<br /><br />&nbsp;&nbsp;&nbsp; // Copy data from the response to standard output<br />&nbsp;&nbsp;&nbsp; n, err := io.Copy(os.Stdout, response.Body)<br />&nbsp;&nbsp;&nbsp; if err != nil {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; log.Fatal(err)<br />&nbsp;&nbsp;&nbsp; }<br /><br />&nbsp;&nbsp;&nbsp; log.Println(&quot;Number of bytes copied to STDOUT:&quot;, n)<br />}</code></pre>



<a name="make_http_get_request_with_timeout"></a>
<h2>Make an HTTP GET request with timeout</h2>
<p>When using <strong>http.Get()</strong> to make a request, it uses the default HTTP client with default settings. If you want to override the settings you need to create your own client and use that to make the request. This example demonstrates how to create an <strong>http.Client</strong> and use it to make a request.</p>

<pre class="prettyprint"><code>// make_http_request_with_timeout.go<br />package main<br /><br />import (<br />&nbsp;&nbsp;&nbsp; &quot;io&quot;<br />&nbsp;&nbsp;&nbsp; &quot;log&quot;<br />&nbsp;&nbsp;&nbsp; &quot;net/http&quot;<br />&nbsp;&nbsp;&nbsp; &quot;os&quot;<br />&nbsp;&nbsp;&nbsp; &quot;time&quot;<br />)<br /><br />func main() {<br />&nbsp;&nbsp;&nbsp; // Create HTTP client with timeout<br />&nbsp;&nbsp;&nbsp; client := &amp;http.Client{<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Timeout: 30 * time.Second,<br />&nbsp;&nbsp;&nbsp; }<br /><br />&nbsp;&nbsp;&nbsp; // Make request<br />&nbsp;&nbsp;&nbsp; response, err := client.Get(&quot;https://www.devdungeon.com/&quot;)<br />&nbsp;&nbsp;&nbsp; if err != nil {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; log.Fatal(err)<br />&nbsp;&nbsp;&nbsp; }<br />&nbsp;&nbsp;&nbsp; defer response.Body.Close()<br /><br />&nbsp;&nbsp;&nbsp; // Copy data from the response to standard output<br />&nbsp;&nbsp;&nbsp; n, err := io.Copy(os.Stdout, response.Body)<br />&nbsp;&nbsp;&nbsp; if err != nil {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; log.Fatal(err)<br />&nbsp;&nbsp;&nbsp; }<br /><br />&nbsp;&nbsp;&nbsp; log.Println(&quot;Number of bytes copied to STDOUT:&quot;, n)<br />}</code></pre>



<a name="set_http_headers_change_user_agent"></a>
<h2>Set HTTP headers (Change user agent)</h2>

<p>In the first example we saw how to use the default HTTP client to make a request. Then we saw how to create out own client so we could customize the settings, like the timeout. Similarly, the HTTP clients use a default <strong>Request</strong> type which we can also customize. This example will walk through creating a request and modifying the headers before sending.</p>

<p>I highly recommed being a good net citizen and providing a descriptive user agent with a string that is easily parsable with a regular expression and contains a link to a website or GitHub repo so a network admin can learn about what the bot is and rate limit or block your bot if it causes problems.</p>

<pre class="prettyprint"><code># Example of a decent bot user agent<br />MyScraperBot v1.0 https://www.github.com/username/MyNanoBot - This bot does x, y, z</code></pre>

<p>Another reason to change your user agent might be to impersonate a different user agent. The default Go user agent may get blocked and you might have to impersonate a Firefox browser. It can also be useful for testing applications to see how they behave when various mobile and desktop user agents are presented.</p>

<p>This example will demonstrate how to change the HTTP headers before sending your request. To set your user agent, you will need to add/override the User-Agent header. Note you can change any header this way, including your cookies, if you wanted to manually manage them. We'll talk more about the cookies later. This only requires the standard library.</p>

<pre class="prettyprint"><code>// http_request_change_headers.go<br />package main<br /><br />import (<br />&nbsp;&nbsp;&nbsp; &quot;io&quot;<br />&nbsp;&nbsp;&nbsp; &quot;log&quot;<br />&nbsp;&nbsp;&nbsp; &quot;net/http&quot;<br />&nbsp;&nbsp;&nbsp; &quot;os&quot;<br />&nbsp;&nbsp;&nbsp; &quot;time&quot;<br />)<br /><br />func main() {<br />&nbsp;&nbsp;&nbsp; // Create HTTP client with timeout<br />&nbsp;&nbsp;&nbsp; client := &amp;http.Client{<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Timeout: 30 * time.Second,<br />&nbsp;&nbsp;&nbsp; }<br /><br />&nbsp;&nbsp;&nbsp; // Create and modify HTTP request before sending<br />&nbsp;&nbsp;&nbsp; request, err := http.NewRequest(&quot;GET&quot;, &quot;https://www.devdungeon.com&quot;, nil)<br />&nbsp;&nbsp;&nbsp; if err != nil {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; log.Fatal(err)<br />&nbsp;&nbsp;&nbsp; }<br />&nbsp;&nbsp;&nbsp; request.Header.Set(&quot;User-Agent&quot;, &quot;Not Firefox&quot;)<br /><br />&nbsp;&nbsp;&nbsp; // Make request<br />&nbsp;&nbsp;&nbsp; response, err := client.Do(request)<br />&nbsp;&nbsp;&nbsp; if err != nil {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; log.Fatal(err)<br />&nbsp;&nbsp;&nbsp; }<br />&nbsp;&nbsp;&nbsp; defer response.Body.Close()<br /><br />&nbsp;&nbsp;&nbsp; // Copy data from the response to standard output<br />&nbsp;&nbsp;&nbsp; _, err = io.Copy(os.Stdout, response.Body)<br />&nbsp;&nbsp;&nbsp; if err != nil {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; log.Fatal(err)<br />&nbsp;&nbsp;&nbsp; }<br />}</code></pre>





<a name="download_a_url"></a>
<h2>Download a URL</h2>
<p>You may want to simply download the contents of a page and store it for offline review at a later date, or download a binary file after determining what URL contains the file you want. This example demonstrates how to make an HTTP request and stream the contents to a file. This only requires the standard library.</p>
<pre class="prettyprint"><code>// download_url.go<br />package main<br /><br />import (<br />&nbsp;&nbsp;&nbsp; &quot;io&quot;<br />&nbsp;&nbsp;&nbsp; &quot;log&quot;<br />&nbsp;&nbsp;&nbsp; &quot;net/http&quot;<br />&nbsp;&nbsp;&nbsp; &quot;os&quot;<br />)<br /><br />func main() {<br />&nbsp;&nbsp;&nbsp; // Make request<br />&nbsp;&nbsp;&nbsp; response, err := http.Get(&quot;https://www.devdungeon.com/archive&quot;)<br />&nbsp;&nbsp;&nbsp; if err != nil {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; log.Fatal(err)<br />&nbsp;&nbsp;&nbsp; }<br />&nbsp;&nbsp;&nbsp; defer response.Body.Close()<br /><br />&nbsp;&nbsp;&nbsp; // Create output file<br />&nbsp;&nbsp;&nbsp; outFile, err := os.Create(&quot;output.html&quot;)<br />&nbsp;&nbsp;&nbsp; if err != nil {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; log.Fatal(err)<br />&nbsp;&nbsp;&nbsp; }<br />&nbsp;&nbsp;&nbsp; defer outFile.Close()<br /><br />&nbsp;&nbsp;&nbsp; // Copy data from HTTP response to file<br />&nbsp;&nbsp;&nbsp; _, err = io.Copy(outFile, response.Body)<br />&nbsp;&nbsp;&nbsp; if err != nil {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; log.Fatal(err)<br />&nbsp;&nbsp;&nbsp; }<br />}</code></pre>






<a name="substring_matching"></a>
<h2>Use substring matching to find page title</h2>
<p>Probably the simplest way to search for something in an HTML document is to do a regular substring match. You will need to first convert the response in to a string and then use the <strong>strings</strong> package in the standard library to do substring searches. This is not my preferred way of searching for things, but it can be viable depending on what you are looking for. It is definitely worth knowing and understanding this technique in case you want to use it. Thanks <a href="https://www.reddit.com/r/golang/comments/86xrek/web_scraping_with_go/dw9i8yb/" target="_blank">xiegeo</a> for reminding me to include this section.</p>

<p>Next we will look at using regular expressions, which are even more powerful than simple substring matches. After that, we'll look at using the <strong>goquery</strong> package to parse the HTML DOM and look for data in a structured way using jQuery like syntax.</p>

<pre class="prettyprint"><code>// substring_matching.go<br />package main<br /><br />import (<br />&nbsp;&nbsp;&nbsp; &quot;fmt&quot;<br />&nbsp;&nbsp;&nbsp; &quot;io/ioutil&quot;<br />&nbsp;&nbsp;&nbsp; &quot;log&quot;<br />&nbsp;&nbsp;&nbsp; &quot;net/http&quot;<br />&nbsp;&nbsp;&nbsp; &quot;os&quot;<br />&nbsp;&nbsp;&nbsp; &quot;strings&quot;<br />)<br /><br />func main() {<br />&nbsp;&nbsp;&nbsp; // Make HTTP GET request<br />&nbsp;&nbsp;&nbsp; response, err := http.Get(&quot;https://www.devdungeon.com/&quot;)<br />&nbsp;&nbsp;&nbsp; if err != nil {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; log.Fatal(err)<br />&nbsp;&nbsp;&nbsp; }<br />&nbsp;&nbsp;&nbsp; defer response.Body.Close()<br /><br />&nbsp;&nbsp;&nbsp; // Get the response body as a string<br />&nbsp;&nbsp;&nbsp; dataInBytes, err := ioutil.ReadAll(response.Body)<br />&nbsp;&nbsp;&nbsp; pageContent := string(dataInBytes)<br /><br />&nbsp;&nbsp;&nbsp; // Find a substr<br />&nbsp;&nbsp;&nbsp; titleStartIndex := strings.Index(pageContent, &quot;&lt;title&gt;&quot;)<br />&nbsp;&nbsp;&nbsp; if titleStartIndex == -1 {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; fmt.Println(&quot;No title element found&quot;)<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; os.Exit(0)<br />&nbsp;&nbsp;&nbsp; }<br />&nbsp;&nbsp;&nbsp; // The start index of the title is the index of the first<br />&nbsp;&nbsp;&nbsp; // character, the &lt; symbol. We don&#039;t want to include<br />&nbsp;&nbsp;&nbsp; // &lt;title&gt; as part of the final value, so let&#039;s offset<br />&nbsp;&nbsp;&nbsp; // the index by the number of characers in &lt;title&gt;<br />&nbsp;&nbsp;&nbsp; titleStartIndex += 7<br /><br />&nbsp;&nbsp;&nbsp; // Find the index of the closing tag<br />&nbsp;&nbsp;&nbsp; titleEndIndex := strings.Index(pageContent, &quot;&lt;/title&gt;&quot;)<br />&nbsp;&nbsp;&nbsp; if titleEndIndex == -1 {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; fmt.Println(&quot;No closing tag for title found.&quot;)<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; os.Exit(0)<br />&nbsp;&nbsp;&nbsp; }<br /><br />&nbsp;&nbsp;&nbsp; // (Optional)<br />&nbsp;&nbsp;&nbsp; // Copy the substring in to a separate variable so the<br />&nbsp;&nbsp;&nbsp; // variables with the full document data can be garbage collected<br />&nbsp;&nbsp;&nbsp; pageTitle := []byte(pageContent[titleStartIndex:titleEndIndex])<br /><br />&nbsp;&nbsp;&nbsp; // Print out the result<br />&nbsp;&nbsp;&nbsp; fmt.Printf(&quot;Page title: %s\n&quot;, pageTitle)<br />}</code></pre>






<a name="using_regular_expressions_to_find_html_comments"></a>
<h2>Use regular expressions to find HTML comments</h2>
<p>
Regular expressions are a powerful way of searching for text patterns. I am providing one example of using regular expressions for reference, but I do not recommend using this method unless you have no other choice. In the next examples, I will look at using goquery, an easier way of finding data in a structured HTML document.
</p>
<pre class="prettyprint"><code>// find_html_comments_with_regex.go<br />package main<br /><br />import (<br />&nbsp;&nbsp;&nbsp; &quot;fmt&quot;<br />&nbsp;&nbsp;&nbsp; &quot;io/ioutil&quot;<br />&nbsp;&nbsp;&nbsp; &quot;log&quot;<br />&nbsp;&nbsp;&nbsp; &quot;net/http&quot;<br />&nbsp;&nbsp;&nbsp; &quot;regexp&quot;<br />)<br /><br />func main() {<br />&nbsp;&nbsp;&nbsp; // Make HTTP request<br />&nbsp;&nbsp;&nbsp; response, err := http.Get(&quot;https://www.devdungeon.com&quot;)<br />&nbsp;&nbsp;&nbsp; if err != nil {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; log.Fatal(err)<br />&nbsp;&nbsp;&nbsp; }<br />&nbsp;&nbsp;&nbsp; defer response.Body.Close()<br /><br />&nbsp;&nbsp;&nbsp; // Read response data in to memory<br />&nbsp;&nbsp;&nbsp; body, err := ioutil.ReadAll(response.Body)<br />&nbsp;&nbsp;&nbsp; if err != nil {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; log.Fatal(&quot;Error reading HTTP body. &quot;, err)<br />&nbsp;&nbsp;&nbsp; }<br /><br />&nbsp;&nbsp;&nbsp; // Create a regular expression to find comments<br />&nbsp;&nbsp;&nbsp; re := regexp.MustCompile(&quot;&lt;!--(.|\n)*?--&gt;&quot;)<br />&nbsp;&nbsp;&nbsp; comments := re.FindAllString(string(body), -1)<br />&nbsp;&nbsp;&nbsp; if comments == nil {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; fmt.Println(&quot;No matches.&quot;)<br />&nbsp;&nbsp;&nbsp; } else {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for _, comment := range comments {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; fmt.Println(comment)<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<br />&nbsp;&nbsp;&nbsp; }<br />}</code></pre>









<a name="find_all_links_on_page"></a>
<h2>Use goquery to find all links on a page</h2>
<p>This example will make use of the goquery package to parse the HTML DOM and let us search for specific elements in a convenient, jQuery-like way. We perform the HTTP request like normal, and then create a goquery document using the response. With the goquery document object, we can call <strong>Find()</strong> and process each element found. In this case, we will search for <strong>a</strong> elements, or links.</p>

<p>I am only scratching the surface of what <a href="https://github.com/PuerkitoBio/goquery" target="_blank">goquery</a> can do. Here is an example of what it can do:</p>

<pre class="prettyprint"><code>// Example of a more complex goquery to find an element in the DOM<br />// https://github.com/PuerkitoBio/goquery<br />document.Find(&quot;.sidebar-reviews article .content-block&quot;)</code></pre>

<p>This is a full working example of how to use goquery to find all the links on a page and print them out.</p>

<pre class="prettyprint"><code>// find_links_in_page.go<br />package main<br /><br />import (<br />&nbsp;&nbsp;&nbsp; &quot;fmt&quot;<br />&nbsp;&nbsp;&nbsp; &quot;log&quot;<br />&nbsp;&nbsp;&nbsp; &quot;net/http&quot;<br /><br />&nbsp;&nbsp;&nbsp; &quot;github.com/PuerkitoBio/goquery&quot;<br />)<br /><br />// This will get called for each HTML element found<br />func processElement(index int, element *goquery.Selection) {<br />&nbsp;&nbsp;&nbsp; // See if the href attribute exists on the element<br />&nbsp;&nbsp;&nbsp; href, exists := element.Attr(&quot;href&quot;)<br />&nbsp;&nbsp;&nbsp; if exists {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; fmt.Println(href)<br />&nbsp;&nbsp;&nbsp; }<br />}<br /><br />func main() {<br />&nbsp;&nbsp;&nbsp; // Make HTTP request<br />&nbsp;&nbsp;&nbsp; response, err := http.Get(&quot;https://www.devdungeon.com&quot;)<br />&nbsp;&nbsp;&nbsp; if err != nil {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; log.Fatal(err)<br />&nbsp;&nbsp;&nbsp; }<br />&nbsp;&nbsp;&nbsp; defer response.Body.Close()<br /><br />&nbsp;&nbsp;&nbsp; // Create a goquery document from the HTTP response<br />&nbsp;&nbsp;&nbsp; document, err := goquery.NewDocumentFromReader(response.Body)<br />&nbsp;&nbsp;&nbsp; if err != nil {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; log.Fatal(&quot;Error loading HTTP response body. &quot;, err)<br />&nbsp;&nbsp;&nbsp; }<br /><br />&nbsp;&nbsp;&nbsp; // Find all links and process them with the function<br />&nbsp;&nbsp;&nbsp; // defined earlier<br />&nbsp;&nbsp;&nbsp; document.Find(&quot;a&quot;).Each(processElement)<br />}</code></pre>





<a name="parse_urls"></a>
<h2>Parse URLs</h2>
<p>In the previous example we looked at finding all the links on a page. A common task after that is to examine the URL and determine if it is a relative URL that leads somewhere on the same site, or a URL that leads off-site somewhere. You can use the string functions to search and parsae the URL manually, but there is a better way!</p>
<p>The Go standard library provides a convenient <strong>URL</strong> type that can handle all of the URL string parsing for us. Let it handle the heavy lifting with string parsing, and just get the hostname, port, query, requestURI, using the predefined functions. Read more about the <strong>url</strong> package and the <strong>url.URL</strong> type at <a href="https://golang.org/pkg/net/url/" target="_blank">https://golang.org/pkg/net/url/</a>.</p>
<pre class="prettyprint"><code>// parse_urls.go<br />package main<br /><br />import (<br />&nbsp;&nbsp;&nbsp; &quot;fmt&quot;<br />&nbsp;&nbsp;&nbsp; &quot;log&quot;<br />&nbsp;&nbsp;&nbsp; &quot;net/url&quot;<br />)<br /><br />func main() {<br />&nbsp;&nbsp;&nbsp; // Parse a complex URL<br />&nbsp;&nbsp;&nbsp; complexUrl := &quot;https://www.example.com/path/to/?query=123&amp;this=that#fragment&quot;<br />&nbsp;&nbsp;&nbsp; parsedUrl, err := url.Parse(complexUrl)<br />&nbsp;&nbsp;&nbsp; if err != nil {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; log.Fatal(err)<br />&nbsp;&nbsp;&nbsp; }<br /><br />&nbsp;&nbsp;&nbsp; // Print out URL pieces<br />&nbsp;&nbsp;&nbsp; fmt.Println(&quot;Scheme: &quot; + parsedUrl.Scheme)<br />&nbsp;&nbsp;&nbsp; fmt.Println(&quot;Host: &quot; + parsedUrl.Host)<br />&nbsp;&nbsp;&nbsp; fmt.Println(&quot;Path: &quot; + parsedUrl.Path)<br />&nbsp;&nbsp;&nbsp; fmt.Println(&quot;Query string: &quot; + parsedUrl.RawQuery)<br />&nbsp;&nbsp;&nbsp; fmt.Println(&quot;Fragment: &quot; + parsedUrl.Fragment)<br /><br />&nbsp;&nbsp;&nbsp; // Get the query key/values as a map<br />&nbsp;&nbsp;&nbsp; fmt.Println(&quot;\nQuery values:&quot;)<br />&nbsp;&nbsp;&nbsp; queryMap := parsedUrl.Query()<br />&nbsp;&nbsp;&nbsp; fmt.Println(queryMap)<br /><br />&nbsp;&nbsp;&nbsp; // Craft a new URL from scratch<br />&nbsp;&nbsp;&nbsp; var customURL url.URL<br />&nbsp;&nbsp;&nbsp; customURL.Scheme = &quot;https&quot;<br />&nbsp;&nbsp;&nbsp; customURL.Host = &quot;google.com&quot;<br />&nbsp;&nbsp;&nbsp; newQueryValues := customURL.Query()<br />&nbsp;&nbsp;&nbsp; newQueryValues.Set(&quot;key1&quot;, &quot;value1&quot;)<br />&nbsp;&nbsp;&nbsp; newQueryValues.Set(&quot;key2&quot;, &quot;value2&quot;)<br />&nbsp;&nbsp;&nbsp; customURL.Fragment = &quot;bookmarkLink&quot;<br />&nbsp;&nbsp;&nbsp; customURL.RawQuery = newQueryValues.Encode()<br /><br />&nbsp;&nbsp;&nbsp; fmt.Println(&quot;\nCustom URL:&quot;)<br />&nbsp;&nbsp;&nbsp; fmt.Println(customURL.String())<br />}</code></pre>






<a name="find_all_images_on_page"></a>
<h2>Use goquery to find all images on a page</h2>
<p>
We can also leverage the <strong>goquery</strong> package to search for other elements. This is another simple example similar to finding the links on a page. This example will show how to search for images on a page and list the URLs. This example is written slightly different, to demonstrate how to create an anonymous function to handle the processing instead of a named function.
</p>

<pre class="prettyprint"><code>// find_images_in_page.go<br />package main<br /><br />import (<br />&nbsp;&nbsp;&nbsp; &quot;fmt&quot;<br />&nbsp;&nbsp;&nbsp; &quot;log&quot;<br />&nbsp;&nbsp;&nbsp; &quot;net/http&quot;<br /><br />&nbsp;&nbsp;&nbsp; &quot;github.com/PuerkitoBio/goquery&quot;<br />)<br /><br />func main() {<br />&nbsp;&nbsp;&nbsp; // Make HTTP request<br />&nbsp;&nbsp;&nbsp; response, err := http.Get(&quot;https://www.devdungeon.com&quot;)<br />&nbsp;&nbsp;&nbsp; if err != nil {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; log.Fatal(err)<br />&nbsp;&nbsp;&nbsp; }<br />&nbsp;&nbsp;&nbsp; defer response.Body.Close()<br /><br />&nbsp;&nbsp;&nbsp; // Create a goquery document from the HTTP response<br />&nbsp;&nbsp;&nbsp; document, err := goquery.NewDocumentFromReader(response.Body)<br />&nbsp;&nbsp;&nbsp; if err != nil {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; log.Fatal(&quot;Error loading HTTP response body. &quot;, err)<br />&nbsp;&nbsp;&nbsp; }<br /><br />&nbsp;&nbsp;&nbsp; // Find and print image URLs<br />&nbsp;&nbsp;&nbsp; document.Find(&quot;img&quot;).Each(func(index int, element *goquery.Selection) {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; imgSrc, exists := element.Attr(&quot;src&quot;)<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if exists {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; fmt.Println(imgSrc)<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<br />&nbsp;&nbsp;&nbsp; })<br />}</code></pre>




<a name="make_http_post_request_with_data"></a>
<h2>Make HTTP POST request with data</h2>
<p>Making a POST request is similar to a GET request. In fact, it is as simple as changing the word "GET" to "POST" in the request. However, a POST request is often accompanied with a payload. This could be a binary file or a URL encoded form. This example will demonstrate how to make a POST request with URL encoded form data and how to post a file like when uploading a file..</p>
<pre class="prettyprint"><code>// http_post_with_payload.go<br />package main<br /><br />import (<br />&nbsp;&nbsp;&nbsp; &quot;log&quot;<br />&nbsp;&nbsp;&nbsp; &quot;net/http&quot;<br />&nbsp;&nbsp;&nbsp; &quot;net/url&quot;<br />)<br /><br />func main() {<br /><br />&nbsp;&nbsp;&nbsp; response, err := http.PostForm(<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;http://example.com/form&quot;,<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; url.Values{<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;username&quot;: {&quot;MyUsername&quot;},<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;password&quot;: {&quot;123&quot;},<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; },<br />&nbsp;&nbsp;&nbsp; )<br />&nbsp;&nbsp;&nbsp; if err != nil {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; log.Fatal(err)<br />&nbsp;&nbsp;&nbsp; }<br />&nbsp;&nbsp;&nbsp; defer response.Body.Close()<br /><br />&nbsp;&nbsp;&nbsp; log.Println(response.Header) // Print the response headers<br /><br />&nbsp;&nbsp;&nbsp; // To upload a file, use Post instead of PostForm, provide<br />&nbsp;&nbsp;&nbsp; // a content type like application/json or application/octet-stream,<br />&nbsp;&nbsp;&nbsp; // and then provide the an io.Reader with the data<br /><br />&nbsp;&nbsp;&nbsp; // http.Post(&quot;http://example.com/upload&quot;, &quot;image/jpeg&quot;, &amp;buff)<br />}</code></pre>





<a name="make_http_request_with_cookie"></a>
<h2>Make HTTP request with cookie</h2>
<p>Since cookies are simply HTTP headers, you can manually set and manage cookies yourself by checking and setting the header values as needed.</p>

<p>Go offers a better way of managing cookies with a <strong>Cookie</strong> type that is used by the <strong>Request</strong> and <strong>Response</strong> type. You can see the source code for the <strong>Cookie</strong> at <a href="https://golang.org/src/net/http/cookie.go" target="_blank">https://golang.org/src/net/http/cookie.go</a></p>

<p>These are some of the cookie functions available on the <strong>Request</strong> and <strong>Response</strong> types:</p>
<pre class="prettyprint"><code>// Cookie functions for Request <br />// https://golang.org/pkg/net/http/#Request<br />Request.AddCookie()&nbsp; // Add cookie to request<br />Request.Cookie()&nbsp;&nbsp;&nbsp;&nbsp; // Get specific cookie<br />Request.Cookies()&nbsp;&nbsp;&nbsp; // Get all cookies<br /><br />// Cookie functions for Response<br />// https://golang.org/pkg/net/http/#Response<br />Response.Cookies()&nbsp;&nbsp; // Get all cookies</code></pre>

<p>Alternatively, you could use a library that is not part of the standard library like the <a href="https://github.com/gorilla/sessions" target="_blank">sessions package provided by Gorilla</a>, but that will not be covered here.</p>

<p>There is also a <strong>cookiejar</strong> type. It is essentially a collection of cookies separated by URL. You can read more about at <a href="https://golang.org/pkg/net/http/cookiejar/" target="_blank">https://golang.org/pkg/net/http/cookiejar/</a>. It is useful if you need to manage cookies for multiple sites.</p>

<pre class="prettyprint"><code>// http_request_with_cookie.go<br />package main<br /><br />import (<br />&nbsp;&nbsp;&nbsp; &quot;fmt&quot;<br />&nbsp;&nbsp;&nbsp; &quot;log&quot;<br />&nbsp;&nbsp;&nbsp; &quot;net/http&quot;<br />)<br /><br />func main() {<br />&nbsp;&nbsp;&nbsp; request, err := http.NewRequest(&quot;GET&quot;, &quot;https://www.devdungeon.com&quot;, nil)<br />&nbsp;&nbsp;&nbsp; if err != nil {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; log.Fatal(err)<br />&nbsp;&nbsp;&nbsp; }<br /><br />&nbsp;&nbsp;&nbsp; // Create a new cookie with the only required fields<br />&nbsp;&nbsp;&nbsp; myCookie := &amp;http.Cookie{<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Name:&nbsp; &quot;cookieKey1&quot;,<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Value: &quot;value1&quot;,<br />&nbsp;&nbsp;&nbsp; }<br /><br />&nbsp;&nbsp;&nbsp; // Add the cookie to your request<br />&nbsp;&nbsp;&nbsp; request.AddCookie(myCookie)<br /><br />&nbsp;&nbsp;&nbsp; // Ask the request to tell us about itself,<br />&nbsp;&nbsp;&nbsp; // just to confirm the cookie attached properly<br />&nbsp;&nbsp;&nbsp; fmt.Println(request.Cookies())<br />&nbsp;&nbsp;&nbsp; fmt.Println(request.Header)<br /><br />&nbsp;&nbsp;&nbsp; // Do something with the request<br />&nbsp;&nbsp;&nbsp; // client := &amp;http.Client{}<br />&nbsp;&nbsp;&nbsp; // client.Do(request)<br />}</code></pre>


<a name="log_in_to_website"></a>
<h2>Log in to a website</h2>

<p>Logging in to a site is relatively simple conceptually. You make an HTTP POST to a specific URL containing your username and password, and it returns a cookie, which is simply an HTTP header, that contains a unique key that matches your session on the server. Most websites work the same in this regard, although custom authentication mechanisms, CAPTCHAs, two-factor authentication, and other security measures complicate this process.</p>

<p>Logging in to a site is going to have to be tailored specifically to your target website. You will have to reverse engineer the authentication process from the site. Many websites use a simple form-based login system. Inside a browser like Chrome or Firefox, you can right click on one of the form fields and choose "inspect". This will allow you to see how the form is constructed, what the target action url is, and how the form fields are named in order to recreate the request programmatically.</p>

<p>You can inspect the form in the source of the HTML, or you can monitor the network traffic itself. The brwoser extensions will let you see the POST requests going on behind the scene on a website, but you could use other tools as well like jsfiddler, burp suite, Zed Attack Proxy (ZAP), or any other man-in-the-middle proxying tool.</p>

<p>Typically, you will need to get the URL in the <strong>action</strong> attribute of the <strong>form</strong>, and the <strong>name</strong> attribute of the of the username and password <strong>input</strong> fields. Once you have that information, you can make the POST request to the URL, and then store the session cookie the server provides in its response. You will need to pass the session cookie with any subsequent requests you make to the server.</p>

<p>Because every website has it's own mechanism for authentication, I am only covering this at the conceptual level and not providing a code example.</p>



<a name="crawling"></a>
<h2>Web crawling</h2>
<p>Crawling is simply an extension of scraping. We already looked at how to <a href="#find_all_links_on_page">find all links on a page</a>, and how to <a href="#parse_urls">parse URLs</a>, which are the important steps. You want to find all the links on a page, parse the url, decide if you want to follow it, and then make a request to the new url, repeating the process.</p>

<p>After parsing a URL, you can determine whether it belongs to the same site you are already on, or leads to another website. You can also look for a file extension at the end of the URL for clues about what it leads to.</p>

<p>You can crawl in a breadth-first or a depth-first manner. One depth-first approach would be to crawl only URLs from the same website before crawling the next website in the list. A breadth-first approach would be to prioritize links that lead to websites you have never seen before.</p>

<p>For a code example of a web crawler, check out the DevDungeon Web Genome project in the next section.</p>

<a name="webgenome_project"></a>
<h2>DevDungeon Project: Web Genome</h2>
<p>Web Genome is a breadth first web crawler that stores HTTP headers in a MongoDB database with a web interface all written in Go. Read more on the <a href="/content/web-genome">Web Genome project page</a> and browse the source code at <a href="https://github.com/DevDungeon/WebGenome" target="_blank">https://github.com/DevDungeon/WebGenome</a>.</p>
<p>Visit the Web Genome website at <a href="http://www.webgeno.me" target="_blank">http://www.webgeno.me</a>.</p>



<a name="conclusion"></a>
<h2>Conclusion</h2>
<p>With this reference code, you should be able to perform basic web scraping tasks to suit your needs. There are also more features in the goquery library that I have not covered. Refer to the official repository at <a href="https://github.com/PuerkitoBio/goquery" target="_blank">https://github.com/PuerkitoBio/goquery</a> for the latest information.</p>

</div></div></div><div id="disqus_thread"><noscript><p><a href="http://devdungeon.disqus.com/?url=https%3A%2F%2Fwww.devdungeon.com%2Fcontent%2Fweb-scraping-go">View the discussion thread.</a></p></noscript></div>    


     <footer>
     <div class="field field-name-field-tags field-type-taxonomy-term-reference field-label-above"><div class="field-label">Tags:&nbsp;</div><div class="field-items"><div class="field-item even"><a href="/tags/go" typeof="skos:Concept" property="rdfs:label skos:prefLabel" datatype="">Go</a></div><div class="field-item odd"><a href="/tags/web-scraping" typeof="skos:Concept" property="rdfs:label skos:prefLabel" datatype="">Web Scraping</a></div><div class="field-item even"><a href="/tags/web-crawling" typeof="skos:Concept" property="rdfs:label skos:prefLabel" datatype="">Web Crawling</a></div><div class="field-item odd"><a href="/tags/http" typeof="skos:Concept" property="rdfs:label skos:prefLabel" datatype="">HTTP</a></div></div></div>     <ul class="links list-inline"><li class="blog_usernames_blog first last"><a href="/blogs/nanodano" title="Read NanoDano&#039;s latest blog entries.">NanoDano&#039;s blog</a></li>
</ul>  </footer>
      </article>

</section>
<section id="block-block-15" class="block block-block clearfix">

      
  <center>
<p style="font-size: 50%;">Advertisement</p>
<!-- 728x90Leaderboard -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-6890888622534407"
     data-ad-slot="9701133649"
     data-ad-format="auto"></ins>
<p style="font-size: 50%;">Advertisement</p>
</center>

</section>
  </div>
    </section>

          <aside class="col-sm-3" role="complementary">
          <div class="region region-sidebar-second">
    <section id="block-search-form" class="block block-search clearfix">

      
  <form class="form-search content-search" action="/content/web-scraping-go" method="post" id="search-block-form" accept-charset="UTF-8"><div><div>
      <h2 class="element-invisible">Search form</h2>
    <div class="input-group"><input title="Enter the terms you wish to search for." placeholder="Search" class="form-control form-text" type="text" id="edit-search-block-form--2" name="search_block_form" value="" size="15" maxlength="128" /><span class="input-group-btn"><button type="submit" class="btn btn-primary"><span class="icon glyphicon glyphicon-search" aria-hidden="true"></span>
</button></span></div><div class="form-actions form-wrapper form-group" id="edit-actions"><button class="element-invisible btn btn-primary form-submit" type="submit" id="edit-submit" name="op" value="Search">Search</button>
</div><input type="hidden" name="form_build_id" value="form-T1RxWqXGqeyUC6W0jmSnOBuiH7cSHo1TMG_9PDkeqQQ" />
<input type="hidden" name="form_id" value="search_block_form" />
</div>
</div></form>
</section>
<section id="block-block-13" class="block block-block clearfix">

      
  <center><p>Join me on Discord!</p>
<a href="/discord" target="_blank"><img src="/sites/default/static/discord_join_dark.png" style="max-width:100%" /></a>
</center>

</section>
<section id="block-block-11" class="block block-block clearfix">

      
  <center>
<p><a href="https://www.youtube.com/DevDungeon" alt="DevDungeon YouTube channel" target="_blank">DevDungeon YouTube Channel<br />
<img src="/sites/all/themes/devdungeon2/icons/youtube-icon.png" style="max-width:33%; max-height: 64px;"/></a></p>

<!--
<p><a href="https://github.com/DevDungeon" alt="DevDungeon GitHub page" target="_blank">DevDungeon GitHub Profile<br />
<img src="/sites/all/themes/devdungeon2/icons/github-icon.png" style="max-width:33%; max-height: 64px;" /></a></p>

<p><a href="/rss.xml" alt="DevDungeon RSS feed" target="_blank">DevDungeon RSS Feed<br />
<img src="/sites/all/themes/devdungeon2/icons/rss-icon.png" style="max-width:33%; max-height: 64px;" /></a></p>
-->
</center>

</section>
<section id="block-views-related-posts-block" class="block block-views clearfix">

        <h2 class="block-title">Related Posts</h2>
    
  <div class="view view-related-posts view-id-related_posts view-display-id-block view-dom-id-397feb667ab459ea2c73785723225f36">
        
  
  
      <div class="view-content">
      <div class="item-list">    <ul>          <li class="views-row views-row-1 views-row-odd views-row-first">  
  <div class="views-field views-field-title">        <span class="field-content"><a href="/content/how-add-trusted-ca-certificate-centosfedora">How to add trusted CA certificate on CentOS/Fedora</a></span>  </div></li>
          <li class="views-row views-row-2 views-row-even">  
  <div class="views-field views-field-title">        <span class="field-content"><a href="/content/ajax-http-requests-vanilla-javascript">AJAX HTTP Requests with Vanilla JavaScript</a></span>  </div></li>
          <li class="views-row views-row-3 views-row-odd">  
  <div class="views-field views-field-title">        <span class="field-content"><a href="/content/live-coding-python-web-scraping-crawling">Live Coding: Python Web Scraping &amp; Crawling</a></span>  </div></li>
          <li class="views-row views-row-4 views-row-even">  
  <div class="views-field views-field-title">        <span class="field-content"><a href="/content/live-coding-port-scanners-c-go-python-java">Live Coding: Port scanners in C, Go, Python, Java</a></span>  </div></li>
          <li class="views-row views-row-5 views-row-odd">  
  <div class="views-field views-field-title">        <span class="field-content"><a href="/content/nginx-tutorial">Nginx Tutorial</a></span>  </div></li>
          <li class="views-row views-row-6 views-row-even">  
  <div class="views-field views-field-title">        <span class="field-content"><a href="/content/one-line-http-servers">One-line HTTP servers</a></span>  </div></li>
          <li class="views-row views-row-7 views-row-odd">  
  <div class="views-field views-field-title">        <span class="field-content"><a href="/content/letsencrypt-free-ssl-certificate-tutorial">LetsEncrypt Free SSL Certificate Tutorial</a></span>  </div></li>
          <li class="views-row views-row-8 views-row-even">  
  <div class="views-field views-field-title">        <span class="field-content"><a href="/content/security-go-my-book-now-published">Security with Go - My book now published!</a></span>  </div></li>
          <li class="views-row views-row-9 views-row-odd">  
  <div class="views-field views-field-title">        <span class="field-content"><a href="/content/making-tor-http-requests-go">Making Tor HTTP Requests with Go</a></span>  </div></li>
          <li class="views-row views-row-10 views-row-even">  
  <div class="views-field views-field-title">        <span class="field-content"><a href="/content/im-speaking-gophercon-about-packet-capturing">I&#039;m Speaking at GopherCon about Packet Capturing</a></span>  </div></li>
          <li class="views-row views-row-11 views-row-odd">  
  <div class="views-field views-field-title">        <span class="field-content"><a href="/content/working-files-go">Working with Files in Go</a></span>  </div></li>
          <li class="views-row views-row-12 views-row-even">  
  <div class="views-field views-field-title">        <span class="field-content"><a href="/content/ip-geolocation-go">IP Geolocation in Go</a></span>  </div></li>
          <li class="views-row views-row-13 views-row-odd">  
  <div class="views-field views-field-title">        <span class="field-content"><a href="/content/packet-capture-injection-and-analysis-gopacket">Packet Capture, Injection, and Analysis with Gopacket</a></span>  </div></li>
          <li class="views-row views-row-14 views-row-even">  
  <div class="views-field views-field-title">        <span class="field-content"><a href="/content/working-images-go">Working with Images in Go</a></span>  </div></li>
          <li class="views-row views-row-15 views-row-odd views-row-last">  
  <div class="views-field views-field-title">        <span class="field-content"><a href="/content/2d-arrays-and-slices-go">2D Arrays and Slices in Go</a></span>  </div></li>
      </ul></div>    </div>
  
  
  
  
  
  
</div>
</section>
<section id="block-block-16" class="block block-block clearfix">

      
  <center>Buy my book!<br /><a href="https://www.packtpub.com/networking-and-servers/security-go" target="_blank"><img src="https://static.packt-cdn.com/products/9781788627917/cover/smaller" style="max-width: 100%;" /></a>
</center>

</section>
<section id="block-block-19" class="block block-block clearfix">

      
  <center><p>Sign up for site monitoring!</p><p><a href="https://www.uppora.net"><img src="/sites/default/static/UpporaAd1.png" style="max-width: 100%;" /></a></p></center>
</section>
<section id="block-block-9" class="block block-block clearfix">

      
  <!-- Begin MailChimp Signup Form -->
<center><p>Join the mailing list!</p></center>
<link href="//cdn-images.mailchimp.com/embedcode/classic-10_7.css" rel="stylesheet" type="text/css">
<style type="text/css">
	#mc_embed_signup{clear:left; font:14px Helvetica,Arial,sans-serif; }
	/* Add your own MailChimp form style overrides in your site stylesheet or in this style block.
	   We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
        #mc_embed_signup .button { color: #00FAE0; background-color: #484a4e; }
</style>
<div id="mc_embed_signup">
<form action="//devdungeon.us13.list-manage.com/subscribe/post?u=61624d2c6e561c44d29013a83&amp;id=4ebc97a4f7" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
<div class="mc-field-group">
	<label for="mce-EMAIL">Email Address  <span class="asterisk">*</span>
</label>
	<input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL">
</div>
<div class="mc-field-group">
	<label for="mce-FNAME">Name</label>
	<input type="text" value="" name="FNAME" class="" id="mce-FNAME">
</div>
	<div id="mce-responses" class="clear">
		<div class="response" id="mce-error-response" style="display:none"></div>
		<div class="response" id="mce-success-response" style="display:none"></div>
	</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_61624d2c6e561c44d29013a83_4ebc97a4f7" tabindex="-1" value=""></div>
    <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>
<script type='text/javascript' src='//s3.amazonaws.com/downloads.mailchimp.com/js/mc-validate.js'></script><script type='text/javascript'>(function($) {window.fnames = new Array(); window.ftypes = new Array();fnames[0]='EMAIL';ftypes[0]='email';fnames[1]='FNAME';ftypes[1]='text';fnames[2]='LNAME';ftypes[2]='text';}(jQuery));var $mcj = jQuery.noConflict(true);</script>
<!--End mc_embed_signup-->
</section>
  </div>
      </aside>  <!-- /#sidebar-second -->
    
  </div>
</div>

  <footer class="footer container">
      <div class="region region-footer">
    <section id="block-block-6" class="block block-block clearfix">

      
  <center>
<p style="font-size: 50%;">Advertisement</p>
<!-- 728x90Leaderboard -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-6890888622534407"
     data-ad-slot="9701133649"
     data-ad-format="auto"></ins>
<p style="font-size: 50%;">Advertisement</p>
</center>

</section>
<section id="block-block-1" class="block block-block clearfix">

        <h2 class="block-title">About DevDungeon</h2>
    
  DevDungeon.com is a virtual hackerspace community with resources for developers and hackers.
</section>
<section id="block-block-4" class="block block-block clearfix">

        <h2 class="block-title">Links</h2>
    
  <ul>
<li><a href="https://www.youtube.com/DevDungeon" target="_blank">YouTube.com/DevDungeon</a></li>
<li><a href="https://www.github.com/DevDungeon" target="_blank">GitHub.com/DevDungeon</a></li>
<li><a href="/discord">DevDungeon Discord Server</a></li>
<li><a href="/rss.xml">RSS Feed</a></li>
<hr />
<li><a href="https://www.polkdesigncompany.com/" target="_blank">Polk Design Company</a></li>
<hr />
<li><a href="/content/privacy-policy">Privacy Policy</a></li>
<li><a href="/sitemap.xml">XML Sitemap</a></li>
</ul>
</section>
<section id="block-block-2" class="block block-block clearfix">

        <h2 class="block-title">About Me</h2>
    
  <ul style="font-size:75%">
 <li>Read more <a href="https://www.devdungeon.com/content/about-me">about me</a>.</li>
 <li>Get my <a href="https://www.devdungeon.com/gpg">public PGP key</a>.</li>
 <li>Email: <a href="mailto:nanodano@devdungeon.com">nanodano@devdungeon.com</a></li>
 <li>XMPP: <a href="xmpp:nanodano@devdungeon.com">nanodano@devdungeon.com</a></li>
</ul>

</section>
  </div>
  </footer>
  <script src="https://www.devdungeon.com/sites/default/files/js/js_MRdvkC2u4oGsp5wVxBG1pGV5NrCPW3mssHxIn6G9tGE.js"></script>
</body>
</html>
